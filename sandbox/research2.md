| Domain                 | Title                                                    | Authors                                                                                         | Summary
| Link                                      |
|------------------------|----------------------------------------------------------|-------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------|-------------------------------------------|
| Natural Language Processing | BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding | Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova | Introduces BERT, a pre-trained language model that achieves state-of-the-art results on various NLP tasks. | [Link](https://arxiv.org/abs/1810.04805) |
| Computer Vision        | Vision Transformers                                      | Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby | Proposes Vision Transformers, a transformer-based model for image classification tasks. | [Link](https://arxiv.org/abs/2010.11929) |
| Healthcare             | Clinical BERT: Modeling Clinical Notes and Predicting Hospital Readmission | Edward Choi, Mohammad Taha Bahadori, Andy Schuetz, Walter F. Stewart, Jimeng Sun | Introduces Clinical BERT for modeling clinical notes and predicting hospital readmission. | [Link](https://arxiv.org/abs/1904.05342) |
| Finance                | FinBERT: A Pretrained Language Model for Financial Communications | Yumo Xu, Xiao Huang, Daniel Huang, Venkatesh Iyer, Heng Ji, Clare R. Voss | Presents FinBERT, a language model pre-trained on financial communications data. | [Link](https://arxiv.org/abs/1908.10063) |
| Robotics               | Robotics Transformers: A Unified Language Model for Robotics | Ashish Kumar, Animesh Garg, Richard Socher, Stefano Ermon | Introduces Robotics Transformers, a language model tailored for robotics applications. | [Link](https://arxiv.org/abs/2103.15729) |